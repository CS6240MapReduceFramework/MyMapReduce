package client;

import java.io.*;
import java.lang.*;

import textsock.TextSocket;

import java.util.*;
import java.util.zip.GZIPInputStream;

import com.amazonaws.auth.*;
import com.amazonaws.services.s3.*;
import com.amazonaws.services.s3.model.*;
import com.amazonaws.AmazonClientException;
import com.amazonaws.AmazonServiceException;
import com.amazonaws.auth.profile.ProfileCredentialsProvider;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3Client;
import com.amazonaws.services.s3.model.PutObjectRequest;
import com.amazonaws.services.s3.model.CopyObjectRequest;
import com.amazonaws.services.s3.transfer.TransferManager;
import com.amazonaws.services.s3.transfer.Upload;
import com.amazonaws.services.s3.transfer.MultipleFileDownload;
import com.amazonaws.services.s3.transfer.Copy;
import com.amazonaws.services.s3.transfer.MultipleFileUpload;
import org.apache.commons.io.FileUtils;

public class WebClient {

    static Properties prop = new Properties();
    public static int partCounter = 1;
    public static int sizeOfFiles = 1024 * 1024 * 128;
    public static byte[] buffer = new byte[sizeOfFiles];

    //FilePaths
    public static String inputFilePath;  //To retrieve Input files in s3://inputBucket/inputFolder
    public static String outputFilePath; //To write output files s3://outputBucket/outputFolder
    public static String inputBucket; //Just the bucket name within s3
    public static String inputPath; //path within input Bucket
    public static String outputBucket; //Just the bucket name within s3
    public static String outputPath; //path within the outputbucket

    // These local folders are deleted after the files are uploaded to s3
    public static String temporaryDataDivision; //Local copy of divided files stored here
    public static String temporaryMergedFiles; // Local copy of merged files with temp files generated by Mapper task
    public static String temporaryFilesFromMapper; //Local copy of temporary files from Mapper task

    static {
        try {
            //Properties file should be within src folder
            prop.load(new FileInputStream("../config.properties"));
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }

    public static ArrayList<String> outputRecords = new ArrayList<String>();
    static private AWSCredentials credentials = new BasicAWSCredentials(prop.getProperty("AWSAccessKeyId"), prop.getProperty("AWSSecretKey"));
    static private AmazonS3 s3Client = new AmazonS3Client(credentials);
    static private TransferManager tx = new TransferManager(credentials);


    //Instance wise input folder containing divided input files from client
    public String getInstanceInputPath(String instanceIp) {
        return "s3://" + inputBucket + "/" + instanceIp + "/input";
    }

    //Tempfiles copied from Mapper task of server
    public String getInstanceOutputPath(String instanceIp) {
        return "s3://" + inputBucket + "/" + instanceIp + "/output";
    }

    //Contains merged and divided files from Client (ready to be copied for reduce task)
    public String getInstanceTempFilesPath(String instanceIp) {
        return "s3://" + inputBucket + "/" + instanceIp + "/temp";
    }

    /*
     * Fetches the list of file names in s3://<inputBucket>/input folder
     * Input Arguments: nil
     * Returns: ArrayList<String>  - List of file names in the given s3 folder
     */
    public static ArrayList<String> getFilesList(String bucketfolder) {
        ArrayList<String> files = new ArrayList<String>();
        try {
            ListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(inputBucket).withPrefix(bucketfolder + "/");
            ObjectListing objectListing;

            do {
                objectListing = s3Client.listObjects(listObjectsRequest);

                for (S3ObjectSummary objectSummary : objectListing.getObjectSummaries()) {
                    if (!objectSummary.getKey().equals(bucketfolder + "/"))
                        files.add(objectSummary.getKey());
                }

                listObjectsRequest.setMarker(objectListing.getNextMarker());
            } while (objectListing.isTruncated());

        } catch (AmazonServiceException ase) {
            System.out.println("AmazonServiceException");
            ase.printStackTrace();
        } catch (AmazonClientException ace) {
            System.out.println("AmazonClientException");
        } finally {
            return files;
        }
    }


    public static void handleSingleFile(String key, String bucketFolder) {

        divideSingleFile(key);
        uploadPartsToS3(bucketFolder);
        bakMainS3File(key);
    }

    public static void divideSingleFile(String key) {

        try {
            String fileExtension = getFileExtension(key);
            if (fileExtension.equals("gz")) {
                divideCompressedFile(key);
            } else {
                divideRegularFile(key);
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static String getFileExtension(String fileName) {
        return fileName.substring(fileName.lastIndexOf(".") + 1);
    }

    public static void divideCompressedFile(String key) throws IOException {

        S3Object object = s3Client.getObject(new GetObjectRequest(inputBucket, key));
        GZIPInputStream gis = new GZIPInputStream(object.getObjectContent());
        BufferedInputStream bis = new BufferedInputStream(gis);

        String fileName = key.substring(key.lastIndexOf("/") + 1, key.lastIndexOf("."));
        writeToFiles(bis, fileName);

        bis.close();
        gis.close();
    }

    public static void divideRegularFile(String key) throws IOException {

        S3Object object = s3Client.getObject(new GetObjectRequest(inputBucket, key));
        BufferedInputStream bis = new BufferedInputStream(object.getObjectContent());
        String fileName = key.substring(key.lastIndexOf("/") + 1);
        writeToFiles(bis, fileName);
        bis.close();
    }

    public static void writeToFiles(BufferedInputStream bis, String fileName) throws IOException {

        File dataDir = new File(temporaryDataDivision);
        dataDir.mkdir();
        int tmp = 0;
        while ((tmp = bis.read(buffer)) > 0) {
            File newFile = new File(String.format("%03d", partCounter++) + "-" + fileName);
            try (FileOutputStream out = new FileOutputStream(temporaryDataDivision + "/" + newFile)) {
                out.write(buffer, 0, tmp);
            }
        }
    }

    public static void uploadPartsToS3(String bucketFolder) {

        File uploadDir = new File(temporaryDataDivision);
        File[] listOfFiles = uploadDir.listFiles();
        for (int i = 0; i < listOfFiles.length; i++) {
            s3Client.putObject(new PutObjectRequest(inputBucket, bucketFolder + "/" + listOfFiles[i].getName(), listOfFiles[i]));
            listOfFiles[i].delete();
        }
        uploadDir.delete();
    }

    public static void bakMainS3File(String key) {

        try {
            //Bakup of input file
            CopyObjectRequest copyObjRequest = new CopyObjectRequest(
                    inputBucket, key, inputBucket, "BakInputFiles/" + key);

            Copy cp = tx.copy(copyObjRequest);
            cp.waitForCompletion();
            s3Client.deleteObject(new DeleteObjectRequest(inputBucket, key));

        } catch (AmazonServiceException ase) {
            System.out.println("Error Message:    " + ase.getMessage());
        } catch (AmazonClientException ace) {
            System.out.println("Error Message: " + ace.getMessage());
        } catch (InterruptedException ioe) {
            System.out.println("error message in threadl.sleep");
        }

    }

    public static void divideFilesInS3(int instancesCount, String[] ips, String bucketfolder, Boolean move) {
        ArrayList<String> files = getFilesList(bucketfolder);

        if (files.size() == 1) {
            handleSingleFile(files.get(0), bucketfolder);
            files = getFilesList(bucketfolder);
        }

        int chunk_size = files.size() / instancesCount;
        int remaining_chunk_size = files.size() % instancesCount;

        System.out.println("Total number of files (after division) - " + files.size());

        int instance = 0;
        System.out.println("Copying files to respective instance folders...");

        for (int i = 0; i < files.size(); i++) {
            try {
                // Copying object
                CopyObjectRequest copyObjRequest = new CopyObjectRequest(
                        inputBucket, files.get(i), outputBucket, ips[instance] + "/" + files.get(i));

                Copy cp = tx.copy(copyObjRequest);
                cp.waitForCompletion();
                if (move)
                    s3Client.deleteObject(new DeleteObjectRequest(outputBucket, files.get(i)));
                instance++;
                if (instance == instancesCount)
                    instance = 0;

            } catch (AmazonServiceException ase) {
                System.out.println("Error Message:    " + ase.getMessage());
            } catch (AmazonClientException ace) {
                System.out.println("Error Message: " + ace.getMessage());
            } catch (InterruptedException ioe) {
                System.out.println("error message in threadl.sleep");
            }
        }
    }

    public static void startMappersPhase(TextSocket[] connections) throws IOException {
        for (TextSocket connection : connections)
            connection.putln("MAPPER_START");
    }

    public static void startReducersPhase(TextSocket[] connections) throws IOException {
        System.out.println("sending REDUCER_START signal to all instances");
        for (TextSocket connection : connections)
            connection.putln("REDUCER_START");
    }

    public static void waitForMappersPhaseCompletion(TextSocket[] connections) throws IOException {
        for (TextSocket connection : connections)
            connection.getln();
    }

    public static void closeConnections(TextSocket[] connections) throws IOException {
        System.out.println("REDUCER_COMPLETE signal receieved. Closing all connections");
        for (TextSocket connection : connections) {
            connection.getln();
            connection.close();
        }
        System.out.println("All connections closed successfully!");

    }

    public static void downloadOutputPartFilesFromS3(String[] ips, String outputBucket) {
        try {

            //TODO: Remove hard-coding of the output folder
            File localFolder = new File("FinalOutput");
            if (!localFolder.exists())
                localFolder.mkdirs();

            for (int i = 0; i < ips.length; i++) {
                MultipleFileDownload md = tx.downloadDirectory(outputBucket, "output", localFolder);
                md.waitForCompletion();
            }

            System.out.println("All output part files from S3://<outputBucket>/output downloaded");

        } catch (AmazonServiceException ase) {
            System.out.println("AmazonServiceException");
            ase.printStackTrace();
        } catch (AmazonClientException ace) {
            System.out.println("AmazonClientException");
            ace.printStackTrace();
        } catch (Exception e) {
            System.out.println("Excepton");
            e.printStackTrace();
        }
    }

    public static void downloadIntermediateFilesFromS3(String[] ips) {
        try {
            File localFolder = new File(temporaryFilesFromMapper);
            if (!localFolder.exists())
                localFolder.mkdirs();

            for (int i = 0; i < ips.length; i++) {
                MultipleFileDownload md = tx.downloadDirectory(outputBucket, ips[i] + "/" + temporaryFilesFromMapper, localFolder);
                md.waitForCompletion();
            }
            System.out.println("All temp files from all instances downloaded");
        } catch (AmazonServiceException ase) {
            System.out.println("AmazonServiceException");
            ase.printStackTrace();
        } catch (AmazonClientException ace) {
            System.out.println("AmazonClientException");
            ace.printStackTrace();
        } catch (Exception e) {
            System.out.println("Excepton");
            e.printStackTrace();
        }
    }

    public static void uploadMergedFilesToS3(String localfolder, String bucketName, String bucketFolder) {

        try {
            File local = new File(localfolder);
            System.out.println("Uploading files to S3 from a local folder\n");

            MultipleFileUpload mu = tx.uploadDirectory(bucketName, bucketFolder, local, true);
            mu.waitForCompletion();
            s3Client.deleteObject(new DeleteObjectRequest(bucketName, "output/.DS_Store"));

        } catch (AmazonServiceException ase) {
            ase.printStackTrace();
        } catch (AmazonClientException ace) {
            ace.printStackTrace();
        } catch (Exception e) {
            e.printStackTrace();
        }

        FileUtils.deleteQuietly(new File(temporaryMergedFiles));

    }

    public static void mergeIntermediateFilesFromS3() throws IOException {

        File tempfiles = new File(temporaryFilesFromMapper);

        if (!tempfiles.exists())
            System.out.println("Folder not found");

        FileWriter fileWriter;
        BufferedWriter bufferedWriter;
        //Open all instance folders in allTempFiles
        for (File instance : tempfiles.listFiles()) {

            if (instance.getName().contains("DS_Store")) {
                continue;
            }

            System.out.println("Opened the temp folder from the instance - " + instance);

            //Open each instance folder
            File subFolder = new File(instance.getAbsolutePath() + "/tempFiles");

            //Iterate over all tempfiles in each isntance folder
            for (File tempFile : subFolder.listFiles()) {

                if (instance.getName().contains("DS_Store")) {
                    continue;
                }
                //Open tempfile for read
                FileReader tmpFileReader = new FileReader(tempFile);
                BufferedReader bufferedReader = new BufferedReader(tmpFileReader);
                String line = "";

                //Open file in parent folder for writing the tempfile
                File fdir = new File(temporaryMergedFiles);
                if (!fdir.exists())
                    fdir.mkdirs();

                File f = new File(temporaryMergedFiles + "/" + tempFile.getName());

                if (!f.exists())
                    f.createNewFile();

                //create writer to copy all the content from tempfile to one tempfile in parent folder(true as second property)
                fileWriter = new FileWriter(f, true);
                bufferedWriter = new BufferedWriter(fileWriter);

                //read lines from temp instance file
                while ((line = bufferedReader.readLine()) != null) {

                    //write to one file
                    bufferedWriter.write(line + "\n");
                    bufferedWriter.flush();
                }

                //close writer
                bufferedWriter.close();
                //close reader
                bufferedReader.close();
                //delete the temp file

            }

        }
        FileUtils.deleteQuietly(new File(temporaryFilesFromMapper));
    }

    public static void deleteEmptyFolderS3(String bucketName, String folderToDelete) {
        try {
            s3Client.deleteObject(new DeleteObjectRequest(bucketName, folderToDelete));
        } catch (AmazonServiceException ase) {
            ase.printStackTrace();
        } catch (AmazonClientException ace) {
            ace.printStackTrace();
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    /* WebClient takes in 3 arguments:

        args[0] = Input file bucket   	Ex: s3://<inputBucket>/input
        args[1] = Output file bucket	Ex: s3://<outputBucket>/output
        args[2] = Instances.txt		- 	A file with list of instances created by start-cluster.sh and their details
        args[3] = Program name		- 	Should match with the application name in the server. Ex: WordCount. Not Word Count
     */
    public static void main(String[] args) throws IOException {

        if (args.length != 2) {
            System.out.println("Not enough arguments passed");
            System.out.println("Usage: WebClient s3://<inputBucket>/input s3://<outputBucket>/output");
            System.exit(1);
        }

        //static FilePaths for entire Program usage
        String inputFilePath = args[0];
        String outputFilePath = args[1];

        String[] inputDataLocationSplits = inputFilePath.split("//")[1].split("/");
        inputBucket = inputDataLocationSplits[0];
        inputPath = inputDataLocationSplits[1];

        String[] outputDataLocatonSplits = outputFilePath.split("//")[1].split("/");
        outputBucket = outputDataLocatonSplits[0];
        outputPath = outputDataLocatonSplits[1];

        System.out.println("Input Bucket - " + inputBucket);
        System.out.println("Output Bucket - " + outputBucket);
        System.out.println("Input path in s3 - " + inputPath);
        System.out.println("Output path in s3 - " + outputPath);

        temporaryDataDivision = "data";
        temporaryMergedFiles = "merged";
        temporaryFilesFromMapper = "tempFiles";

        //Read the instances.txt file
        System.out.println("Reading instances.txt file");
        Scanner sc = new Scanner(new File("instances.txt"));
        int instances_num = Integer.parseInt(sc.nextLine());
        System.out.println("Instances count: " + instances_num);

        int count = 0;

        String ips_ports[] = new String[instances_num];
        String instanceIp = "";
        TextSocket[] connections = new TextSocket[instances_num];

        //TODO: Convert this sequential code to parallel using Threads
        while (sc.hasNextLine()) {
            String[] line = sc.nextLine().split(";");
            String instance_id = line[0];
            instanceIp = line[1];

            String portNum = line[2];
            ips_ports[count] = instanceIp + "_" + portNum;

            int port = Integer.parseInt(line[2]);
            System.out.println("Establishing connection to: " + instanceIp + " and port - " + port);
            TextSocket conn = new TextSocket(instanceIp, port);

            System.out.println("Connection established..");
            connections[count] = conn;

            count++;

            //send corresponding folder in s3 for this instance
            conn.putln(inputBucket);

            //send instance ip
            conn.putln(instanceIp);

            //send instance port
            conn.putln(portNum);

            //Send the same output folder for all instances
            conn.putln(outputBucket);

            System.out.println("Program started on" + instanceIp);
        }

        divideFilesInS3(instances_num, ips_ports, inputPath, false);
        startMappersPhase(connections);
        waitForMappersPhaseCompletion(connections);

        downloadIntermediateFilesFromS3(ips_ports);

        //Merging files to allTempFiles folder (this deletes the local temporary files folder)
        mergeIntermediateFilesFromS3();

        //Upload to output directory in the input_bucket
        uploadMergedFilesToS3(temporaryMergedFiles, outputBucket, temporaryMergedFiles);
        divideFilesInS3(instances_num, ips_ports, temporaryMergedFiles, true);

        //delete merged folder if exists after moving the files
        deleteEmptyFolderS3(outputBucket, temporaryMergedFiles);

        startReducersPhase(connections);
        closeConnections(connections);

        downloadOutputPartFilesFromS3(ips_ports, outputBucket);

        System.exit(0);
    }

}

